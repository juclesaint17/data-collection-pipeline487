{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Scrapper import IkeaScrapper, Ikea_Furniture, Scrapper\n",
    "import time\n",
    "\n",
    "\n",
    "target1 = Scrapper()\n",
    "\n",
    "#target = Ikea_Furniture()\n",
    "#target.ikea_living.navigate_Ikea_living_rooms_page()\n",
    "time.sleep(1)\n",
    "#target.ikea_living.display_living_room_products()\n",
    "\n",
    "\n",
    "\n",
    "#target.ikea_living.navigate_sofa_beds()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accept_cookies = target1.driver.find_element(By.XPATH, '//button[@id=\"onetrust-accept-btn-handler\"]')\n",
    "accept_cookies.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms = target1.driver.find_element(By.XPATH, '//ul[@class=\"hnf-header__nav__main\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foore =target1.site_pages_links(xpath_category='//ul[@class=\"hnf-header__nav__main\"]' ,item_cat_tag='li')\n",
    "target1.get_webpages_links(foore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "living_stuff = target1.driver.find_element(By.XPATH, '//*[@id=\"5a386581-e41e-11ec-aa30-f1ff1fc0055d\"]/div/div/div[1]/nav')\n",
    "sites = living_stuff.find_elements(By.TAG_NAME, 'a')\n",
    "lists= []\n",
    "for site in sites:\n",
    "    mysite = site.get_attribute('href')\n",
    "    lists.append(mysite)\n",
    "print(lists)\n",
    "for link in lists:\n",
    "    target1.driver.get(link)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(image_path:str, image_tag:str):\n",
    "\n",
    "\n",
    "    '''\n",
    "        Collecting images links for each page and display the links\n",
    "\n",
    "        Parameters:\n",
    "        ------------------------------------------\n",
    "        image_path: the path of images sources\n",
    "        image_source: the source link of the image\n",
    "\n",
    "    '''\n",
    "\n",
    "    images_link = target1.site_pages_links(image_path, image_tag)\n",
    "    images_list = []\n",
    "\n",
    "    for products_imgs in images_link:\n",
    "        images = products_imgs.find_elements(By.XPATH, '//img[@class=\"pip-image\"]')\n",
    "            \n",
    "        for image_src in images:\n",
    "            images = image_src.get_attribute('src')\n",
    "            images_list.append(images)\n",
    "        \n",
    "        print(\"=============PRODUCTS IMAGES URLS===========================\")\n",
    "        print(\"\")\n",
    "        print(\"\\tThe total number of images links is: {}\".format(len(images_list)))\n",
    "        print(images_list)\n",
    "\n",
    "\n",
    "display_images(image_path='//div[@class=\"plp-product-list__products\"]',image_tag='./div')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(im_url, fp):\n",
    "    img_data =  requests.get(im_url).content\n",
    "    with open(fp, 'wb') as stunna:\n",
    "        stunna.write(img_data)\n",
    "\n",
    "def create_dir(fn,img_path):\n",
    "    #path_dir= '/home/juc-lesaint/Desktop/data-collection-pipeline487/'#\n",
    "    #folder = fn\n",
    "    path = os.path.join(img_path, fn)\n",
    "    os.mkdir(path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_dir= '/home/juc-lesaint/Desktop/data-collection-pipeline487/'\n",
    "create_dir(\"P_data8\",path_dir)\n",
    "\n",
    "items_container_path = target1.driver.find_element(By.XPATH, '//div[@class=\"plp-product-list__products\"]')\n",
    "\n",
    "item_path = items_container_path.find_elements(By.XPATH, './div')\n",
    "images_sources = []\n",
    "\n",
    "for products_imgs in item_path:\n",
    "    images = products_imgs.find_elements(By.XPATH, '//img[@class=\"pip-image\"]')\n",
    "    \n",
    "for image_src in images:\n",
    "    images_sources.append(image_src.get_attribute('src'))\n",
    "print(images_sources)\n",
    "print(len(images_sources))\n",
    "\n",
    "for pic in range(len(images_sources)):\n",
    "    \n",
    "    download_image(images_sources[pic], \"P_data8/imgs{}.jpg\".format(pic))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_file(product_code,product_data,file_path):\n",
    "        \n",
    "        product_code = product_code\n",
    "        product_data = product_data\n",
    "        \n",
    "        \n",
    "        #path = '/home/juc-lesaint/Desktop/data-collection-pipeline487/raw_data'\n",
    "        \n",
    "        if not os.path.exists(product_code):\n",
    "            os.chdir(file_path)\n",
    "            time.sleep(1)\n",
    "            os.mkdir(product_code)\n",
    "        with open(f\"{product_code}/data.json\", \"w\") as outfile:\n",
    "            json.dump(product_data, outfile, indent=4)\n",
    "        \n",
    "            \n",
    "\n",
    "'''\n",
    "def download_image(img_source,img_folder):\n",
    "    \n",
    "    image_data = requests.get(img_source).content\n",
    "\n",
    "    with open(img_folder, 'wb') as img_writer:\n",
    "        img_writer.write(image_data)\n",
    "'''\n",
    "\n",
    "\n",
    "def create_dir(dir_path: str,folder_name):\n",
    "        '''\n",
    "        Create a directory in a given file path\n",
    "\n",
    "        Parameters:\n",
    "        dir_path: directory path to create the folder\n",
    "        folder_name: the name of the folder to be created\n",
    "        '''\n",
    "        folder_path = os.path.join(dir_path, folder_name)\n",
    "        try:\n",
    "            if not os.path.exists(folder_path):\n",
    "                \n",
    "                os.mkdir(folder_path)\n",
    "        except:\n",
    "            OSError(\"Folder exist...please create new folder\")\n",
    "\n",
    "            \n",
    "        #os.mkdir(path)\n",
    "\n",
    "\n",
    "items_container_path = target1.driver.find_element(By.XPATH, '//div[@class=\"plp-product-list__products\"]')\n",
    "\n",
    "item_path = items_container_path.find_elements(By.XPATH, './div')\n",
    "mylist = []\n",
    "path_dir= '/home/juc-lesaint/Desktop/data-collection-pipeline487/'\n",
    "dir_name = \"P_stuff5\"\n",
    "\n",
    "create_dir(path_dir,dir_name)\n",
    "time.sleep(1)\n",
    "#products_id =[]\n",
    "images = []\n",
    "products_dict = {\n",
    "    'Time scrapped':[],\n",
    "    'Product Code':[],\n",
    "    'Product Brand': [],\n",
    "    'Product Description': [],\n",
    "    'Product Price(£)': [],\n",
    "    'Product Images':[]\n",
    "    }\n",
    "# getting the dict of all products in a page\n",
    "for item in item_path:\n",
    "    #data_list = item.find_elements(By.XPATH, '//div[@class=\"pip-compact-price-package\"]')\n",
    "    id_lists =  item.find_elements(By.XPATH, '//div[@class=\"pip-product-compact\"]')\n",
    "for product_ref in id_lists:\n",
    "    date = datetime.now()\n",
    "    date_collected = date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    products_dict['Time scrapped'].append(date_collected)\n",
    "    product_code = product_ref.get_attribute(\"data-product-number\")\n",
    "    products_dict['Product Code'].append(product_code)      \n",
    "        #print(product_code)\n",
    "    product_name = product_ref.get_attribute(\"data-product-name\")\n",
    "    products_dict['Product Brand'].append(product_name)\n",
    "        #print(product_name)\n",
    "    product_price = product_ref.get_attribute(\"data-price\")\n",
    "    products_dict['Product Price(£)'].append(product_price)\n",
    "        #print(product_price)\n",
    "    #for prod_img in range(len(products_dict)):\n",
    "        #products_dict[prod_img].append(images[prod_img])\n",
    "   \n",
    "    product_description = product_ref.find_element(By.TAG_NAME, \"a\")\n",
    "    description = product_description.get_attribute(\"aria-label\")\n",
    "    #print(description)\n",
    "    products_dict['Product Description'].append(description)\n",
    "    #print(\"------------------------\")\n",
    "    \n",
    "    product_image = product_ref.find_element(By.TAG_NAME, \"img\")\n",
    "    image = product_image.get_attribute(\"src\")\n",
    "    products_dict['Product Images'].append(image)\n",
    "#print(\"Page dict\")\n",
    "#print(products_dict)\n",
    "\n",
    "   #product_frame = pd.DataFrame.from_dict(products_dict,orient=\"index\")\n",
    "df = pd.DataFrame()\n",
    "lists =[]\n",
    "count =0\n",
    "for index in range(len(products_dict['Product Code'])):\n",
    "    product_data = {\n",
    "\n",
    "        'Time scrapped': products_dict['Time scrapped'][index],\n",
    "        'Product Code': products_dict['Product Code'][index],\n",
    "        'Product Brand': products_dict['Product Brand'][index],\n",
    "        'Product Description':products_dict['Product Description'][index],\n",
    "        'Product Price(£)': products_dict['Product Price(£)'][index],\n",
    "        'Product Images':products_dict['Product Images'][index]   \n",
    "}   \n",
    "    count+=1\n",
    "    df = df.append(product_data, ignore_index=True)\n",
    "    #print(product_data['Product Images'])\n",
    "\n",
    "    path = '/home/juc-lesaint/Desktop/data-collection-pipeline487/P_stuff5'\n",
    "\n",
    "    prod_file_data = str(product_data['Product Code'])\n",
    "    #data_image = product_data['Product Images']\n",
    "\n",
    "    save_file(prod_file_data,product_data,path)\n",
    "    #time.sleep(1)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    #download_image(data_image, f\"P_stuff2/{str(product_data['Time scrapped'])}_{str(product_data['Product Code'])}_{count}.jpg\")\n",
    "\n",
    "    \n",
    "\n",
    "    #product_frame = pd.DataFrame.from_dict(product_data,orient=\"index\")\n",
    "    print(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get product image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST DATA COLLECTION\n",
    "items_container_path = target1.driver.find_element(By.XPATH, '//div[@class=\"plp-product-list__products\"]')\n",
    "\n",
    "item_path = items_container_path.find_elements(By.XPATH, './div')\n",
    "mylist = []\n",
    "products_id =[]\n",
    "data_dict_keys = [\"Brand:\",\"Description:\",\"Price:\",\"Rating:\",\"Product Id:\"]\n",
    "\n",
    "for item in item_path:\n",
    "    data_list = item.find_elements(By.XPATH, '//div[@class=\"pip-compact-price-package\"]')\n",
    "\n",
    "    id_lists =  item.find_elements(By.XPATH, '//div[@class=\"pip-product-compact\"]')\n",
    "\n",
    "\n",
    "for product_ref in id_lists:\n",
    "    data_ref = product_ref.get_attribute(\"data-product-number\")\n",
    "    products_id.append(data_ref.splitlines())\n",
    "#print(products_id)  \n",
    "for datas in data_list:\n",
    "    res= datas.text\n",
    "    mylist.append(res.splitlines())\n",
    "\n",
    "\n",
    "for idx in range(len(mylist)):\n",
    "    #print(products_id[0])\n",
    "    mylist[idx].append(products_id[idx][0])\n",
    "    #print(mylist[idx])\n",
    "    #print(products_id[idx])\n",
    "\n",
    "print(\"\\tLIST OF LIVING ROOM DATA\")\n",
    "for products_items in mylist:\n",
    "    product = products_items\n",
    "    #print(product)\n",
    "    \n",
    "    data_dict = dict(zip(data_dict_keys,product))\n",
    "    \n",
    "    #print(data_dict)\n",
    "    #data_dict.update({\"Product code\":})\n",
    "    \n",
    "    product_data = pd.DataFrame.from_dict(data_dict,orient =\"index\")\n",
    "    #print(\"\")\n",
    "    print(product_data)\n",
    "    #print(\"--------------------------------------------------------\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_container_path = target1.driver.find_element(By.XPATH, '//div[@class=\"plp-product-list__products\"]')\n",
    "item_path = items_container_path.find_elements(By.XPATH, './div')\n",
    "product_id = []\n",
    "\n",
    "for pages in item_path:\n",
    "    \n",
    "    #prod_list.append(pages.text)\n",
    "    pag_links = pages.find_elements(By.XPATH, '//div[@class=\"pip-product-compact\"]')\n",
    "for product_ref in pag_links:\n",
    "\n",
    "    data_ref = product_ref.get_attribute(\"data-product-number\")\n",
    "    product_id.append(data_ref)\n",
    "#print(prod_list)\n",
    "print(product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_container_path = target1.driver.find_element(By.XPATH, '//div[@class=\"plp-product-list__products\"]')\n",
    "item_path = items_container_path.find_elements(By.XPATH, './div')\n",
    "\n",
    "item_list = []\n",
    "dicts_keys= [\"rating\",\"brand\",\"Description\",\"price\",\"rating\",\"delivery option\",\"availability\"]\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for item in item_path:\n",
    "    prod = item.text\n",
    "    item_list.append(prod.splitlines())\n",
    "#print(len(item_list))\n",
    "#print(item_list[2])\n",
    "for product_data in item_list:\n",
    "    #print(product_data)\n",
    "    \n",
    "    new_data = dict(zip(dicts_keys, product_data))\n",
    "    print(new_data)\n",
    "#pd.DataFrame.from_dict(new_data)\n",
    "\n",
    "\n",
    "#prod_dict = {}\n",
    "#for p in range(len(item_list)):\n",
    "    #prod_dict[p]=item_list[p]\n",
    "\n",
    "#print(prod_dict)\n",
    "\n",
    "#for k,v in prod_dict.items():\n",
    "   # datas = v\n",
    "   # print(datas)\n",
    "#print(type(datas))\n",
    "#pd.DataFrame.from_dict(prod_dict)\n",
    "\n",
    "\n",
    "#for v in item_path:\n",
    "   # print(\"total: \",len(v.text))\n",
    "    #print(v.text)\n",
    "#print(item_path)\n",
    "\n",
    "##products_dict = {\n",
    "    #'Brand': [],\n",
    "    #'Product Description': [],\n",
    "    #'Product Price(£)': []\n",
    "    \n",
    "   # }\n",
    "#for item in item_path:\n",
    "\n",
    "    #brand = item.find_element(By.XPATH, '//span[@class=\"pip-header-section__title--small notranslate\"]').text\n",
    "\n",
    "    #products_dict['Brand'].append(brand)\n",
    "    #info = item.find_element(By.XPATH, '//span[@class=\"pip-header-section__description-text\"]').text\n",
    "    #products_dict['Product Description'].append(info)\n",
    "#print(info.text)\n",
    "    #price = item.find_element(By.XPATH, '//span[@class=\"pip-price__integer\"]').text\n",
    "    #products_dict['Product Price(£)'].append(price)\n",
    "#print(len(products_dict))    \n",
    "#print(products_dict)    \n",
    "#pd.DataFrame.from_dict(products_dict)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "product_dict = {\n",
    "    'Brand':[], \n",
    "    'Product Description': [], \n",
    "    'Product Price(£)': [],\n",
    "    'Garantee': []\n",
    "     }\n",
    "product_container = target1.driver.find_element(By.XPATH, '//div[@class=\"pip-product__buy-module-container\"]')\n",
    "prod_data = product_container.find_element(By.XPATH, './/div')\n",
    "\n",
    "brand = prod_data.find_element(By.XPATH, '//span[@class=\"pip-header-section__title--big notranslate\"]').text\n",
    "#print(brand)\n",
    "product_dict['Brand'].append(brand)\n",
    "Infos = prod_data.find_element(By.XPATH, '//span[@class=\"pip-header-section__description-text\"]').text\n",
    "#print(Infos)\n",
    "product_dict['Product Description'].append(Infos)\n",
    "price = prod_data.find_element(By.XPATH, '//span[@class=\"pip-price-price__integer\"]').text\n",
    "product_dict['Product Price(£)'].append(price)\n",
    "#print(price)\n",
    "garantee = prod_data.find_element(By.XPATH, '//span[@class=\"pip-guarantee__text\"]').text\n",
    "product_dict['Garantee'].append(garantee)\n",
    "#print(garantee)\n",
    "\n",
    "#datas = prod_data.text\n",
    "#print(\"----list-----\")\n",
    "#print(datas)\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "\n",
    "    \n",
    "#brand = span_pan.find_element(By.XPATH, '//*[@class=\"pip-header-section__title--small notranslate\"]').text\n",
    "#print(brand)\n",
    "#\n",
    "#print(brand)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict\n",
    "pd.DataFrame.from_dict(product_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get info\n",
    "def get_info(target1):\n",
    "\n",
    "    table = target1.driver.find_element(By.XPATH, '//div[@class=\"pip-product__subgrid product-pip js-product-pip\"]')\n",
    "    columns = table.find_element(By.XPATH, './div')\n",
    "    product_info = columns[0]\n",
    "    #collect info\n",
    "    product_data = target1.driver.retrieve_data(product_info)\n",
    "\n",
    "# retrive info\n",
    "@staticmethod\n",
    "def retrieve_data(target1,column):\n",
    "\n",
    "    rows_count = column.find_element(By.XPATH, './/div')\n",
    "    rows = rows_count.find_element(By.XPATH, './/span')\n",
    "    data_list = []\n",
    "    for row in rows:\n",
    "        data = row.text\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furnitures_dict\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_product = target.driver.find_element(By.XPATH, '//*[@id=\"45471a60-357b-11ec-a8f6-0b949a082dfb\"]/div/div/div[1]/nav')\n",
    "page_product.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to furniture page\n",
    "furniture_category = target.driver.find_element(By.XPATH, '//*[@id=\"pub__carousel__6f52285c-c220-11ec-a3dd-0948e2821b2e\"]/div[1]/div/div/div')\n",
    "furniture_category.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to garden page\n",
    "garden_category = target.driver.find_element(By.XPATH, '//*[@id=\"pub__carousel__6f52285c-c220-11ec-a3dd-0948e2821b2e\"]/div[2]/div/div/div')\n",
    "garden_category.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigate on the available Ikea page links access --good\n",
    "page_nav = target.driver.find_element(By.XPATH, '//ul[@class=\"hnf-header__nav__main\"]')\n",
    "navs= page_nav.find_elements(By.XPATH,'./li')\n",
    "nav_list =[]\n",
    "print(navs)\n",
    "for link_nav in navs:\n",
    "    sub_nav = link_nav.find_element(By.TAG_NAME, 'a')\n",
    "    access_link = sub_nav.get_attribute('href')\n",
    "    nav_list.append(access_link)\n",
    "    \n",
    "print(nav_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display links of available webpages   good.\n",
    "containers = target.driver.find_element(By.XPATH, '//ul[@data-tracking-label=\"products\"]')\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "product_list = containers.find_elements(By.XPATH, './li')\n",
    "menu_product_list =[]\n",
    "for x in product_list:\n",
    "    a_tag = x.find_element(By.TAG_NAME, 'a')\n",
    "    link = a_tag.get_attribute('href')\n",
    "    menu_product_list.append(link)\n",
    "print(f'there are {len(menu_product_list)} products available')\n",
    "print(menu_product_list)\n",
    "\n",
    "big_list =[]\n",
    "\n",
    "for i in range(5):\n",
    "    big_list.extend(menu_product_list)\n",
    "print(f'there are {len(big_list)} products available')\n",
    "print(big_list)\n",
    "\n",
    "    \n",
    "#for page in big_list:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sub_container = containers.find_element(By.XPATH, './span')\n",
    "#print(sub_container.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = target.driver.find_element(By.XPATH, '//*[@id=\"search-results\"]')\n",
    "print(product_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pipelineproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a898363b9a8520275054d8f1adecf87bf6d9c52298a44091dd4a5fae49feb88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
